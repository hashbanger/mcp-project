{
  "2410.15650v1": {
    "title": "Voice-Enabled AI Agents can Perform Common Scams",
    "authors": [
      "Richard Fang",
      "Dylan Bowman",
      "Daniel Kang"
    ],
    "summary": "Recent advances in multi-modal, highly capable LLMs have enabled\nvoice-enabled AI agents. These agents are enabling new applications, such as\nvoice-enabled autonomous customer service. However, with all AI capabilities,\nthese new capabilities have the potential for dual use.\n  In this work, we show that voice-enabled AI agents can perform the actions\nnecessary to perform common scams. To do so, we select a list of common scams\ncollected by the government and construct voice-enabled agents with directions\nto perform these scams. We conduct experiments on our voice-enabled agents and\nshow that they can indeed perform the actions necessary to autonomously perform\nsuch scams. Our results raise questions around the widespread deployment of\nvoice-enabled AI agents.",
    "pdf_url": "http://arxiv.org/pdf/2410.15650v1",
    "published": "2024-10-21"
  },
  "2212.04213v1": {
    "title": "Voice Over Body? Older Adults' Reactions to Robot and Voice Assistant Facilitators of Group Conversation",
    "authors": [
      "Katie Seaborn",
      "Takuya Sekiguchi",
      "Seiki Tokunaga",
      "Norihisa P. Miyake",
      "Mihoko Otake-Matsuura"
    ],
    "summary": "Intelligent agents have great potential as facilitators of group conversation\namong older adults. However, little is known about how to design agents for\nthis purpose and user group, especially in terms of agent embodiment. To this\nend, we conducted a mixed methods study of older adults' reactions to voice and\nbody in a group conversation facilitation agent. Two agent forms with the same\nunderlying artificial intelligence (AI) and voice system were compared: a\nhumanoid robot and a voice assistant. One preliminary study (total n=24) and\none experimental study comparing voice and body morphologies (n=36) were\nconducted with older adults and an experienced human facilitator. Findings\nrevealed that the artificiality of the agent, regardless of its form, was\nbeneficial for the socially uncomfortable task of conversation facilitation.\nEven so, talkative personality types had a poorer experience with the \"bodied\"\nrobot version. Design implications and supplementary reactions, especially to\nagent voice, are also discussed.",
    "pdf_url": "http://arxiv.org/pdf/2212.04213v1",
    "published": "2022-12-08"
  },
  "2308.11786v3": {
    "title": "How Voice and Helpfulness Shape Perceptions in Human-Agent Teams",
    "authors": [
      "Samuel Westby",
      "Richard J. Radke",
      "Christoph Riedl",
      "Brooke Foucault Welles"
    ],
    "summary": "Voice assistants are increasingly prevalent, from personal devices to team\nenvironments. This study explores how voice type and contribution quality\ninfluence human-agent team performance and perceptions of anthropomorphism,\nanimacy, intelligence, and trustworthiness. By manipulating both, we reveal\nmechanisms of perception and clarify ambiguity in previous work. Our results\nshow that the human resemblance of a voice assistant's voice negatively\ninteracts with the helpfulness of an agent's contribution to flip its effect on\nperceived anthropomorphism and perceived animacy. This means human teammates\ninterpret the agent's contributions differently depending on its voice. Our\nstudy found no significant effect of voice on perceived intelligence,\ntrustworthiness, or team performance. We find differences in these measures are\ncaused by manipulating the helpfulness of an agent. These findings suggest that\nfunction matters more than form when designing agents for high-performing\nhuman-agent teams, but controlling perceptions of anthropomorphism and animacy\ncan be unpredictable even with high human resemblance.",
    "pdf_url": "http://arxiv.org/pdf/2308.11786v3",
    "published": "2023-08-22"
  },
  "2205.04149v1": {
    "title": "Identifying synthetic voices qualities for conversational agents",
    "authors": [
      "M. Cuciniello",
      "T. Amorese",
      "G. Cordasco",
      "S. Marrone",
      "F. Marulli",
      "F. Cavallo",
      "O. Gordeeva",
      "Z. Callejas Carri\u00f3n",
      "A. Esposito"
    ],
    "summary": "The present study aims to explore user acceptance and perceptions toward\ndifferent quality levels of synthetical voices. To achieve this, four voices\nhave been exploited considering two main factors: the quality of the voices\n(low vs high) and their gender (male and female). 186 volunteers were recruited\nand subsequently allocated into four groups of different ages respec-tively,\nadolescents, young adults, middle-aged and seniors. After having randomly\nlistened to each voice, participants were asked to fill the Virtual Agent Voice\nAcceptance Questionnaire (VAVAQ). Outcomes show that the two higher quality\nvoices of Antonio and Giulia were more appreciated than the low-quality voices\nof Edoardo and Clara by the whole sample in terms of pragmatic, hedonic and\nattractiveness qualities attributed to the voices. Concerning preferences\ntowards differently aged voices, it clearly appeared that they varied according\nto participants age' ranges examined. Furthermore, in terms of suitability to\nperform different tasks, participants considered Antonio and Giulia equally\nadapt for healthcare and front office jobs. Antonio was also judged to be\nsignificantly more qualified to accomplish protection and security tasks, while\nEdoardo was classified as the absolute least skilled in conducting household\nchores.",
    "pdf_url": "http://arxiv.org/pdf/2205.04149v1",
    "published": "2022-05-09"
  },
  "2401.03581v1": {
    "title": "Evaluating and Personalizing User-Perceived Quality of Text-to-Speech Voices for Delivering Mindfulness Meditation with Different Physical Embodiments",
    "authors": [
      "Zhonghao Shi",
      "Han Chen",
      "Anna-Maria Velentza",
      "Siqi Liu",
      "Nathaniel Dennler",
      "Allison O'Connell",
      "Maja Matari\u0107"
    ],
    "summary": "Mindfulness-based therapies have been shown to be effective in improving\nmental health, and technology-based methods have the potential to expand the\naccessibility of these therapies. To enable real-time personalized content\ngeneration for mindfulness practice in these methods, high-quality\ncomputer-synthesized text-to-speech (TTS) voices are needed to provide verbal\nguidance and respond to user performance and preferences. However, the\nuser-perceived quality of state-of-the-art TTS voices has not yet been\nevaluated for administering mindfulness meditation, which requires emotional\nexpressiveness. In addition, work has not yet been done to study the effect of\nphysical embodiment and personalization on the user-perceived quality of TTS\nvoices for mindfulness. To that end, we designed a two-phase human subject\nstudy. In Phase 1, an online Mechanical Turk between-subject study (N=471)\nevaluated 3 (feminine, masculine, child-like) state-of-the-art TTS voices with\n2 (feminine, masculine) human therapists' voices in 3 different physical\nembodiment settings (no agent, conversational agent, socially assistive robot)\nwith remote participants. Building on findings from Phase 1, in Phase 2, an\nin-person within-subject study (N=94), we used a novel framework we developed\nfor personalizing TTS voices based on user preferences, and evaluated\nuser-perceived quality compared to best-rated non-personalized voices from\nPhase 1. We found that the best-rated human voice was perceived better than all\nTTS voices; the emotional expressiveness and naturalness of TTS voices were\npoorly rated, while users were satisfied with the clarity of TTS voices.\nSurprisingly, by allowing users to fine-tune TTS voice features, the\nuser-personalized TTS voices could perform almost as well as human voices,\nsuggesting user personalization could be a simple and very effective tool to\nimprove user-perceived quality of TTS voice.",
    "pdf_url": "http://arxiv.org/pdf/2401.03581v1",
    "published": "2024-01-07"
  }
}